2020-12-05 16:01:28.369118: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-05 16:01:28.491438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-05 16:01:28.492027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P5000 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:0b:00.0
totalMemory: 15.90GiB freeMemory: 15.63GiB
2020-12-05 16:01:28.492052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-12-05 16:01:28.846781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-05 16:01:28.846829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-12-05 16:01:28.846837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-12-05 16:01:28.846952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15147 MB memory) -> physical GPU (device: 0, name: Quadro P5000, pci bus id: 0000:0b:00.0, compute capability: 6.1)
class_weights {0: 96, 1: 4}
X_train shape: (9606, 1, 32, 231)
X_validate shape: (4803, 1, 32, 231)
X_testshape: (4806, 1, 32, 231)
9606 train samples
4803 validate samples
4806 test samples
chans: 32 samples: 231
Train on 9606 samples, validate on 4803 samples
Epoch 1/50

Epoch 00001: val_loss improved from inf to 0.27082, saving model to /tmp/checkpoint.h5
 - 44s - loss: 0.2544 - acc: 0.9333 - val_loss: 0.2708 - val_acc: 0.9336
Epoch 2/50

Epoch 00002: val_loss improved from 0.27082 to 0.24453, saving model to /tmp/checkpoint.h5
 - 43s - loss: 0.2504 - acc: 0.9336 - val_loss: 0.2445 - val_acc: 0.9336
Epoch 3/50

Epoch 00003: val_loss improved from 0.24453 to 0.24254, saving model to /tmp/checkpoint.h5
 - 43s - loss: 0.2481 - acc: 0.9336 - val_loss: 0.2425 - val_acc: 0.9336
Epoch 4/50

Epoch 00004: val_loss improved from 0.24254 to 0.24234, saving model to /tmp/checkpoint.h5
 - 43s - loss: 0.2471 - acc: 0.9336 - val_loss: 0.2423 - val_acc: 0.9336
Epoch 5/50

Epoch 00005: val_loss did not improve from 0.24234
 - 43s - loss: 0.2452 - acc: 0.9336 - val_loss: 0.2430 - val_acc: 0.9336
Epoch 6/50

Epoch 00006: val_loss did not improve from 0.24234
 - 44s - loss: 0.2431 - acc: 0.9336 - val_loss: 0.2442 - val_acc: 0.9336
Epoch 7/50

Epoch 00007: val_loss did not improve from 0.24234
 - 43s - loss: 0.2420 - acc: 0.9336 - val_loss: 0.2426 - val_acc: 0.9336
Epoch 8/50

Epoch 00008: val_loss did not improve from 0.24234
 - 43s - loss: 0.2397 - acc: 0.9336 - val_loss: 0.2426 - val_acc: 0.9336
Epoch 9/50

Epoch 00009: val_loss did not improve from 0.24234
 - 43s - loss: 0.2394 - acc: 0.9336 - val_loss: 0.2436 - val_acc: 0.9334
Epoch 10/50

Epoch 00010: val_loss did not improve from 0.24234
 - 43s - loss: 0.2368 - acc: 0.9336 - val_loss: 0.2440 - val_acc: 0.9332
Epoch 11/50

Epoch 00011: val_loss did not improve from 0.24234
 - 43s - loss: 0.2360 - acc: 0.9336 - val_loss: 0.2460 - val_acc: 0.9325
Epoch 12/50

Epoch 00012: val_loss improved from 0.24234 to 0.24212, saving model to /tmp/checkpoint.h5
 - 43s - loss: 0.2368 - acc: 0.9336 - val_loss: 0.2421 - val_acc: 0.9332
Epoch 13/50

Epoch 00013: val_loss did not improve from 0.24212
 - 43s - loss: 0.2332 - acc: 0.9336 - val_loss: 0.2428 - val_acc: 0.9336
Epoch 14/50

Epoch 00014: val_loss did not improve from 0.24212
 - 43s - loss: 0.2340 - acc: 0.9336 - val_loss: 0.2458 - val_acc: 0.9332
Epoch 15/50

Epoch 00015: val_loss improved from 0.24212 to 0.24074, saving model to /tmp/checkpoint.h5
 - 43s - loss: 0.2324 - acc: 0.9336 - val_loss: 0.2407 - val_acc: 0.9336
Epoch 16/50

Epoch 00016: val_loss did not improve from 0.24074
 - 43s - loss: 0.2285 - acc: 0.9336 - val_loss: 0.2434 - val_acc: 0.9336
Epoch 17/50

Epoch 00017: val_loss did not improve from 0.24074
 - 42s - loss: 0.2318 - acc: 0.9336 - val_loss: 0.2420 - val_acc: 0.9334
Epoch 18/50

Epoch 00018: val_loss did not improve from 0.24074
 - 42s - loss: 0.2277 - acc: 0.9336 - val_loss: 0.2465 - val_acc: 0.9336
Epoch 19/50

Epoch 00019: val_loss did not improve from 0.24074
 - 43s - loss: 0.2240 - acc: 0.9335 - val_loss: 0.2531 - val_acc: 0.9311
Epoch 20/50

Epoch 00020: val_loss did not improve from 0.24074
 - 43s - loss: 0.2264 - acc: 0.9337 - val_loss: 0.2481 - val_acc: 0.9330
Epoch 21/50

Epoch 00021: val_loss did not improve from 0.24074
 - 42s - loss: 0.2254 - acc: 0.9334 - val_loss: 0.2636 - val_acc: 0.9261
Epoch 22/50

Epoch 00022: val_loss did not improve from 0.24074
 - 42s - loss: 0.2227 - acc: 0.9337 - val_loss: 0.2628 - val_acc: 0.9325
Epoch 23/50

Epoch 00023: val_loss did not improve from 0.24074
 - 43s - loss: 0.2229 - acc: 0.9337 - val_loss: 0.2549 - val_acc: 0.9309
Epoch 24/50

Epoch 00024: val_loss did not improve from 0.24074
 - 42s - loss: 0.2207 - acc: 0.9335 - val_loss: 0.2579 - val_acc: 0.9307
Epoch 25/50

Epoch 00025: val_loss did not improve from 0.24074
 - 42s - loss: 0.2218 - acc: 0.9337 - val_loss: 0.2546 - val_acc: 0.9317
Epoch 26/50

Epoch 00026: val_loss did not improve from 0.24074
 - 43s - loss: 0.2196 - acc: 0.9333 - val_loss: 0.2555 - val_acc: 0.9303
Epoch 27/50

Epoch 00027: val_loss did not improve from 0.24074
 - 42s - loss: 0.2166 - acc: 0.9337 - val_loss: 0.2470 - val_acc: 0.9332
Epoch 28/50

Epoch 00028: val_loss did not improve from 0.24074
 - 43s - loss: 0.2192 - acc: 0.9336 - val_loss: 0.2529 - val_acc: 0.9330
Epoch 29/50

Epoch 00029: val_loss did not improve from 0.24074
 - 42s - loss: 0.2187 - acc: 0.9339 - val_loss: 0.2473 - val_acc: 0.9334
Epoch 30/50

Epoch 00030: val_loss did not improve from 0.24074
 - 41s - loss: 0.2174 - acc: 0.9338 - val_loss: 0.2528 - val_acc: 0.9332
Epoch 31/50

Epoch 00031: val_loss did not improve from 0.24074
 - 43s - loss: 0.2159 - acc: 0.9333 - val_loss: 0.2605 - val_acc: 0.9286
Epoch 32/50

Epoch 00032: val_loss did not improve from 0.24074
 - 43s - loss: 0.2141 - acc: 0.9333 - val_loss: 0.2490 - val_acc: 0.9328
Epoch 33/50

Epoch 00033: val_loss did not improve from 0.24074
 - 43s - loss: 0.2145 - acc: 0.9336 - val_loss: 0.2499 - val_acc: 0.9334
Epoch 34/50

Epoch 00034: val_loss did not improve from 0.24074
 - 43s - loss: 0.2154 - acc: 0.9341 - val_loss: 0.2617 - val_acc: 0.9305
Epoch 35/50

Epoch 00035: val_loss did not improve from 0.24074
 - 42s - loss: 0.2119 - acc: 0.9342 - val_loss: 0.2503 - val_acc: 0.9336
Epoch 36/50

Epoch 00036: val_loss did not improve from 0.24074
 - 43s - loss: 0.2124 - acc: 0.9336 - val_loss: 0.2606 - val_acc: 0.9330
Epoch 37/50

Epoch 00037: val_loss did not improve from 0.24074
 - 43s - loss: 0.2145 - acc: 0.9339 - val_loss: 0.2468 - val_acc: 0.9336
Epoch 38/50

Epoch 00038: val_loss did not improve from 0.24074
 - 43s - loss: 0.2132 - acc: 0.9335 - val_loss: 0.2569 - val_acc: 0.9328
Epoch 39/50

Epoch 00039: val_loss did not improve from 0.24074
 - 42s - loss: 0.2116 - acc: 0.9338 - val_loss: 0.2524 - val_acc: 0.9336
Epoch 40/50

Epoch 00040: val_loss did not improve from 0.24074
 - 42s - loss: 0.2098 - acc: 0.9331 - val_loss: 0.2600 - val_acc: 0.9332
Epoch 41/50

Epoch 00041: val_loss did not improve from 0.24074
 - 43s - loss: 0.2119 - acc: 0.9337 - val_loss: 0.2553 - val_acc: 0.9336
Epoch 42/50

Epoch 00042: val_loss did not improve from 0.24074
 - 43s - loss: 0.2112 - acc: 0.9334 - val_loss: 0.2604 - val_acc: 0.9321
Epoch 43/50

Epoch 00043: val_loss did not improve from 0.24074
 - 42s - loss: 0.2109 - acc: 0.9338 - val_loss: 0.2599 - val_acc: 0.9325
Epoch 44/50

Epoch 00044: val_loss did not improve from 0.24074
 - 42s - loss: 0.2070 - acc: 0.9342 - val_loss: 0.2658 - val_acc: 0.9328
Epoch 45/50

Epoch 00045: val_loss did not improve from 0.24074
 - 42s - loss: 0.2064 - acc: 0.9335 - val_loss: 0.2728 - val_acc: 0.9334
Epoch 46/50

Epoch 00046: val_loss did not improve from 0.24074
 - 42s - loss: 0.2041 - acc: 0.9359 - val_loss: 0.2643 - val_acc: 0.9319
Epoch 47/50

Epoch 00047: val_loss did not improve from 0.24074
 - 43s - loss: 0.2049 - acc: 0.9352 - val_loss: 0.2635 - val_acc: 0.9315
Epoch 48/50

Epoch 00048: val_loss did not improve from 0.24074
 - 43s - loss: 0.2096 - acc: 0.9337 - val_loss: 0.2717 - val_acc: 0.9319
Epoch 49/50

Epoch 00049: val_loss did not improve from 0.24074
 - 43s - loss: 0.2075 - acc: 0.9337 - val_loss: 0.2731 - val_acc: 0.9332
Epoch 50/50

Epoch 00050: val_loss did not improve from 0.24074
 - 43s - loss: 0.2063 - acc: 0.9343 - val_loss: 0.2751 - val_acc: 0.9323
/home/wtsmith/anaconda3/envs/arl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/wtsmith/anaconda3/envs/arl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/wtsmith/anaconda3/envs/arl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/wtsmith/anaconda3/envs/arl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/wtsmith/anaconda3/envs/arl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/wtsmith/anaconda3/envs/arl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])

Bad key "text.kerning_factor" on line 4 in
/home/wtsmith/anaconda3/envs/arl/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template
or from the matplotlib source distribution
Classification accuracy: 0.949022 
roc_auc_score 0.5092559593884818
confusion_matrix
